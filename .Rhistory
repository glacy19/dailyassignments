slice_max(cases, n=6) %>%
pull(state)
covid %>%
filter(date == max(date)) %>%
group_by(state) %>%
summarize(cases = sum(cases, na.rm =TRUE)) %>%
ungroup()
slice_max(cases, n=6) %>%
pull(state)
covid %>%
filter(date == max(date)) %>%
group_by(state) %>%
summarize(cases = sum(cases, na.rm =TRUE)) %>%
ungroup()
slice_max(cases, n=6) %>%
pull(state)
order_by_slice_max(cases, n=6) %>%
covid %>%
filter(date == max(date)) %>%
group_by(state) %>%
summarize(cases = sum(cases, na.rm =TRUE)) %>%
ungroup()
covid%>%
filter(date == max(date)) %>%
group_by(state) %>%
summarize(cases = sum(cases, na.rm =TRUE)) %>%
ungroup()
order_by_slice_max(cases, n=6) %>%
pull(state)
covid%>%
filter(date == max(date)) %>%
group_by(state) %>%
summarize(cases = sum(cases, na.rm =TRUE)) %>%
ungroup()
arrange(desc(cases, n=6)) %>%
pull(state)
covid |>
filter(date == max(date)) |>
group_by(state) |>
summarize(cases = sum(cases, na.rm = TRUE)) |>
ungroup() |>
slice_max(cases, n = 6) |>
pull(state)
covid |>
filter(state %in% c("California", "Texas", "Florida", "New York", "Illinois", "Pennsylvania")) |>
ggplot(aes(x = date, y = cases)) +
geom_line(aes(color = state)) +
facet_wrap(~state) +
theme_gray()
covid%>%
filter(date == max(date)) %>%
group_by(state) %>%
summarize(cases = sum(cases, na.rm =TRUE)) %>%
ungroup()
slice_max(cases, n = 6)
covid %>%
filter(date == max(date)) %>%
group_by(state) %>%
summarize(cases = sum(cases, na.rm = TRUE)) %>%
ungroup() %>%
slice_max(cases, n = 6) %>%
pull(state)
covid %>%
filter(state %in% c("California", "Texas", "Florida", "New York", "Illinois", "Pennsylvania")) %>%
ggplot(aes(x = date, y = cases)) +
geom_line(aes(color = state)) +
facet_wrap(~state) +
theme_minimal()
ggsave(gg, file = "img/Ex7Quest1.png")
covid %>%
filter(date == max(date)) %>%
group_by(state) %>%
summarize(cases = sum(cases, na.rm = TRUE)) %>%
ungroup() %>%
slice_max(cases, n = 6) %>%
pull(state)
top_states
covid %>%
filter(state %in% top_states) %>%
group_by(state, date) %>%
summarize(cases = sum(cases)) %>%
ungroup()
ggplot(aes(x = date, y = cases, color = state)) +
geom_line(size = 2) +
facet_wrap(~state) +
ggthemes::gdocs() +
theme(legend.position = 'NA') +
labs(title = "Total Case Counts",
subtitle = "Data Source: NY-Times",
x = "Date",
y = "Cases",
caption = "Daily Exercise 7")
covid |>
filter(date == max(date)) |>
group_by(state) |>
summarize(cases = sum(cases, na.rm = TRUE)) |>
ungroup() |>
slice_max(cases, n = 6) |>
pull(state) ->
top_states
covid |>
filter(state %in% top_states) |>
group_by(state, date) |>
summarise(cases = sum(cases)) |>
ungroup() |>
ggplot(aes(x = date, y = cases, color = state)) +
geom_line(size = 2) +
facet_wrap(~state) +
ggthemes::theme_gdocs() +
theme(legend.position = 'NA') +
labs(title = "Total Case Counts",
subtitle = "Data Source: NY-Times",
x = "Date",
y = "Cases",
caption = "Daily Exercise 07")
covid |>
filter(date == max(date)) |>
group_by(state) |>
summarize(cases = sum(cases, na.rm = TRUE)) |>
ungroup() |>
slice_max(cases, n = 6) |>
pull(state) ->
top_states
covid |>
filter(state %in% top_states) |>
group_by(state, date) |>
summarize(cases = sum(cases)) |>
ungroup() |>
ggplot(aes(x = date, y = cases, color = state)) +
geom_line(size = 2) +
facet_wrap(~state) +
ggthemes::theme_gdocs() +
theme(legend.position = 'NA') +
labs(title = "Total Case Counts",
subtitle = "Data Source: NY-Times",
x = "Date",
y = "Cases",
caption = "Daily Exercise 07")
covid |>
filter(date == max(date)) |>
group_by(state) |>
summarize(cases = sum(cases, na.rm = TRUE)) |>
ungroup() |>
slice_max(cases, n = 6) |>
pull(state) ->
top_states
covid |>
filter(state %in% top_states) |>
group_by(state, date) |>
summarize(cases = sum(cases)) |>
ungroup() |>
ggplot(aes(x = date, y = cases, color = state)) +
geom_line(size = 2) +
facet_wrap(~state) +
theme_minimal() +
theme(legend.position = 'NA') +
labs(title = "Total Case Counts",
subtitle = "Data Source: NY-Times",
x = "Date",
y = "Cases",
caption = "Daily Exercise 07")
covid %>%
group_by(date) %>%
summarize(cases = sum(cases)) %>%
ggplot(aes(x = date, y = cases)) +
geom_col(fill ="lightblue", color ="lightblue", alpha = ,25) +
geom_line(colos = "navy", size = 3) +
theme_grey() +
labs(title = "Total USA COVID Cases per day",
x = "Date",
y = "Cases",
caption = "Daily Exercise 7")
covid %>%
group_by(date) %>%
summarize(cases = sum(cases)) %>%
ggplot(aes(x = date, y = cases)) +
geom_col(fill ="lightblue", color ="lightblue", alpha = ,25) +
geom_line(color = "navy", size = 3) +
theme_grey() +
labs(title = "Total USA COVID Cases per day",
x = "Date",
y = "Cases",
caption = "Daily Exercise 7")
covid |>
group_by(date) |>
summarize(cases = sum(cases)) |>
ggplot(aes(x = date, y = cases)) +
geom_col(fill = "lightblue", color = "lightblue", alpha = .25) +
geom_line(color = "navy", size = 3) +
ggthemes::theme_gdocs() +
labs(title = "Total USA COVID Cases per day",
x = "Date",
y = "Cases",
caption = "Daily Exercise 07")
covid |>
group_by(date) |>
summarize(cases = sum(cases)) |>
ggplot(aes(x = date, y = cases)) +
geom_col(fill = "lightblue", color = "lightblue", alpha = .25) +
geom_line(color = "navy", size = 3) +
theme_grey() +
labs(title = "Total USA COVID Cases per day",
x = "Date",
y = "Cases",
caption = "Daily Exercise 07")
covid |>
group_by(date) |>
summarize(cases = sum(cases)) |>
ggplot(aes(x = date, y = cases)) +
geom_col(fill = "lightblue", color = "lightblue", alpha = .25) +
geom_line(color = "navy", size = 3) +
theme_grey() +
labs(title = "Total USA COVID Cases per day",
x = "Date",
y = "Cases",
caption = "Daily Exercise 07")
source("C:/Users/gcl61/Git/ESS 330 Exercises/day-07.R/day-07.R")
source("C:/Users/gcl61/Git/ESS 330 Exercises/day-05.R/ex5.html")
source("C:/Users/gcl61/Git/ESS 330 Exercises/day-05.R/Daily Assignment 5.html")
?airquality
airquality
summary(airquality)
shapiro.test(airquality)
source("C:/Users/gcl61/Git/ESS 330 Exercises/day-11.12.R/LinReg.R")
library(tidyverse)
airquality
str(airquality)
summary(airquality)
shapiro.test(airquality$Ozone)
shapiro.test(airquality$Solar.R)
shapiro.test(airquality$Wind)
shapiro.test(airquality$Temp)
library(tidyverse)
data("airquality")
str(airquality)
summary(airquality)
shapiro.test(airquality$Ozone)
shapiro.test(airquality$Solar.R)
shapiro.test(airquality$Wind)
shapiro.test(airquality$Temp)
moments::agostino.test(na.omit(airquality$Ozone))
install.packages("moments")
moments::agostino.test(na.omit(airquality$Ozone))
moments::agostino.test(na.omit(airquality$Solar.R))
moments::agostino.test(na.omit(airquality$Wind))
moments::agostino.test(na.omit(airquality$Temp))
library(tidyverse)
data("airquality")
str(airquality)
summary(airquality)
shapiro.test(airquality$Ozone)
shapiro.test(airquality$Solar.R)
shapiro.test(airquality$Wind)
shapiro.test(airquality$Temp)
## creating a new column with case_when translating the months in 4 seasons
airquality <- airquality%>%
mutate(Season = case_when(
Month %in% c(11,12,1) ~ "Winter",
Month %in% c(2,3,4), ~ "Spring",
Month %in% c(5,6,7) ~ "Summer",
Month %in% c(8,9,10) ~ "Fall"
))
View(airquality)
## creating a new column with case_when translating the months in 4 seasons
airquality <- airquality%>%
mutate(Season = case_when(
Month %in% c(11, 12, 1) ~ "Winter",
Month %in% c(2, 3, 4), ~ "Spring",
Month %in% c(5, 6, 7) ~ "Summer",
Month %in% c(8, 9, 10) ~ "Fall"
))
## creating a new column with case_when translating the months in 4 seasons
airquality <- airquality%>%
mutate(Season = case_when(
Month %in% c(11, 12, 1) ~ "Winter",
Month %in% c(2, 3, 4), ~ "Spring",
Month %in% c(5, 6, 7) ~ "Summer",
Month %in% c(8, 9, 10) ~ "Fall",
TRUE ~ as.character(NA)
))
## creating a new column with case_when translating the months in 4 seasons
airquality <- airquality%>%
mutate(Season = case_when(
Month %in% c(11, 12, 1) = "Winter",
## creating a new column with case_when translating the months in 4 seasons
airquality <- airquality%>%
mutate(Season = case_when(
Month %in% c(11, 12, 1) ~ "Winter",
Month %in% c(2, 3, 4) ~ "Spring",
Month %in% c(5, 6, 7) ~ "Summer",
Month %in% c(8, 9, 10) ~ "Fall"
))
table(airquality$Season)
install.packages("recipe")
## making a recipe with the variables
## prep and bake to generate a processed dataset
library(recipes)
recipe_airquality <- recipe(Ozone ~ Temp + Solar.R + Wind + Season, data = airquality) %>%
step_impute_mean(all_predictors()) %>%
step_normalize(all_predictors()) %>%
step_dummy(all_nominal_predictors())
processed_data <- recipe_airquality %>%
prep() %>%
bake(new_data = NULL)
## making a recipe with the variables
## prep and bake to generate a processed dataset
library(recipes)
mutate(Season = factor(Season))
## making a recipe with the variables
## prep and bake to generate a processed dataset
airquality <- airquality%>%
mutate(Season = case_when(
Month %in% c(11, 12, 1) ~ "Winter",
Month %in% c(2, 3, 4) ~ "Spring",
Month %in% c(5, 6, 7) ~ "Summer",
Month %in% c(8, 9, 10) ~ "Fall"
)) %>%
mutate(Season = factor(Season))
library(recipes)
recipe_airquality <- recipe(Ozone ~ Temp + Solar.R + Wind + Season, data = airquality) %>%
step_impute_mean(Temp, Solar.R, Wind) %>%
step_normalize(Temp, Solar.R,Wind) %>%
step_dummy(Season)
processed_data <- recipe_airquality %>%
prep() %>%
bake(new_data = NULL)
head(processed_data)
## fitting a linear model using ozone as the response variable and all other varibales as predictors
lm_model <- lm(Ozone ~ ., data = processed_data)
summary(lm_model)
library(broom)
library(ggpubr)
install.packages("ggpubr")
library(broom)
library(ggpubr)
augmented_data <- augment(lm_model, data = processed_data)
library(broom)
library(ggpubr)
augmented_data <- augment(lm_model, data = processed_data)
# Load necessary libraries
library(broom)
library(ggpubr)
# Augment data with fitted values and residuals
augmented_data <- augment(lm_model)
# Check for row count consistency
dim(augmented_data)
dim(processed_data)  # Should match
hist(augmented_data$.resid, main = "Residuals Histogram", xlab = "Residuals")
qqnorm(augmented_data$.resid)
qqline(augmented_data$.resid, col = "red")
ggscatter(augmented_data, x = "Ozone", y = ".fitted",
add = "reg.line", conf.int = TRUE,
cor.coef = TRUE, cor.method = "spearman",
ellipse = TRUE)
View(airquality)
View(lm_model)
palmerpenguins
palmerpenguins
?palmerpenguins
??palmerpenguins
install.packages("palmerpenguins")
library(palmerpenguins)
penguins_fold
penguins_split <- initial_split(penguins, prop = 0.7, strata = species)
set.seed(123)
penguins_split <- initial_split(penguins, prop = 0.7, strata = species)
set.seed(123)
library(palmerpenguins)
library(tidymodels)
library(palmerpenguins)
set.seed(123)
(penguins_split <- initial_split(drop_na(penguins), prop = 0.7, strata = species))
penguins_train  <- training(penguins_split)
penguins_test   <- testing(penguins_split)
penguin_folds <- vfold_cv(penguins_train, v = 10)
View(penguin_folds)
penguin_folds <- vfold_cv(penguins_train, v = 5)
install.packages("palmerpenguins")
library(palmerpenguins)
penguins_fold
penguin_folds <- vfold_cv(penguins_train, v = 10)
penguins_folds
View(penguin_folds)
install.packages("ranger")
library(tidymodels)
library(palmerpenguins)
library(ranger)
set.seed(123)
(penguins_split <- initial_split(drop_na(penguins), prop = 0.7, strata = species))
#> <Training/Testing/Total>
#> <265/68/333>
penguins_train  <- training(penguins_split)
penguins_test   <- testing(penguins_split)
penguin_folds <- vfold_cv(penguins_train, v = 10)
penguins_folds
library(tidymodels)
library(palmerpenguins)
library(ranger)
set.seed(123)
(penguins_split <- initial_split(drop_na(penguins), prop = 0.7, strata = species))
#> <Training/Testing/Total>
#> <265/68/333>
penguins_train  <- training(penguins_split)
penguins_test   <- testing(penguins_split)
penguin_folds <- vfold_cv(penguins_train, v = 10)
print(penguin_folds)
set.seed(123)
library(tidymodels)
library(palmerpenguins)
library(ranger)
set.seed(123)
(penguins_split <- initial_split(drop_na(penguins), prop = 0.7, strata = species))
#> <Training/Testing/Total>
#> <265/68/333>
penguins_train  <- training(penguins_split)
penguins_test   <- testing(penguins_split)
penguin_folds <- vfold_cv(penguins_train, v = 10)
penguins_folds
library(tidymodels)
library(palmerpenguins)
library(ranger)
set.seed(123)
(penguins_split <- initial_split(drop_na(penguins), prop = 0.7, strata = species))
#> <Training/Testing/Total>
#> <265/68/333>
penguins_train  <- training(penguins_split)
penguins_test   <- testing(penguins_split)
penguin_folds <- vfold_cv(penguins_train, v = 10)
print(penguins_folds)
library(tidymodels)
library(palmerpenguins)
library(ranger)
set.seed(123)
(penguins_split <- initial_split(drop_na(penguins), prop = 0.7, strata = species))
#> <Training/Testing/Total>
#> <265/68/333>
penguins_train  <- training(penguins_split)
penguins_test   <- testing(penguins_split)
penguin_folds <- vfold_cv(penguins_train, v = 10)
print(penguin_folds)
# defining multinominal logistic regression model, there are 3 species types
multinom_model <- multinom_reg() %>%
set_engine("nnet") %>%
set_mode("classification")
# using default model which is nnet
rand_forest_model <- rand_forest() %>%
set_engine("ranger") %>%
set_mode("classification")
penguins_wf_Set <- workflow_set(
preproc = list(speceis ~ .),
models = list(multinom = multinom_model, rf = rand_forest_model))
# fit both models with the 10 fold cross validation, #fit_resamples is a function from tidymodels ecosystem, specicially in the workflows
penguins_res <- penguins_wf_Set %>%
workflow_map("fit_resamples",
resamples = penguin_folds, control = control_resamples(save_pred = TRUE))
# saving metrics
penguins_res_metrics <- collect_metrics(penguins_res)
# compare
# defining multinominal logistic regression model, there are 3 species types
multinom_model <- multinom_reg() %>%
set_engine("nnet") %>%
set_mode("classification")
# using default model which is nnet
rand_forest_model <- rand_forest() %>%
set_engine("ranger") %>%
set_mode("classification")
penguins_wf_Set <- workflow_set(
preproc = list(species ~ .),
models = list(multinom = multinom_model, rf = rand_forest_model))
# fit both models with the 10 fold cross validation, #fit_resamples is a function from tidymodels ecosystem, specicially in the workflows
penguins_res <- penguins_wf_Set %>%
workflow_map("fit_resamples",
resamples = penguin_folds, control = control_resamples(save_pred = TRUE))
# saving metrics
penguins_res_metrics <- collect_metrics(penguins_res)
# compare
accuracy_comparison <- penguins_res_metrics %>%
filter(.metric == "accuracy")
print(accuracy_comparison)
library(tidymodels)
library(palmerpenguins)
library(ranger)
set.seed(123)
(penguins_split <- initial_split(drop_na(penguins), prop = 0.7, strata = species))
#> <Training/Testing/Total>
#> <265/68/333>
penguins_train  <- training(penguins_split)
penguins_test   <- testing(penguins_split)
penguin_folds <- vfold_cv(penguins_train, v = 10)
print(penguin_folds)
# defining multinominal logistic regression model, there are 3 species types
multinom_model <- multinom_reg() %>%
set_engine("nnet") %>%
set_mode("classification")
# using default model which is nnet
rand_forest_model <- rand_forest() %>%
set_engine("ranger") %>%
set_mode("classification")
penguins_wf_Set <- workflow_set(
preproc = list(species ~ .),
models = list(multinom = multinom_model, rf = rand_forest_model))
# fit both models with the 10 fold cross validation, #fit_resamples is a function from tidymodels ecosystem, specicially in the workflows
penguins_res <- penguins_wf_Set %>%
workflow_map("fit_resamples",
resamples = penguin_folds, control = control_resamples(save_pred = TRUE))
# saving metrics
penguins_res_metrics <- collect_metrics(penguins_res)
# compare
accuracy_comparison <- penguins_res_metrics %>%
filter(.metric == "accuracy")
print(accuracy_comparison)
View(accuracy_comparison)
